import os
import asyncio
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
from aiogram.types import Message
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.storage.memory import MemoryStorage
from rag.rag import RAGKnowledgeBase
import openai  # –î–ª—è Perplexity —á–µ—Ä–µ–∑ OpenAI client

# –ö–ª—é—á–∏
BOT_TOKEN = os.getenv("TELEGRAM_TOKEN")  # Render –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
PPLX_API_KEY = os.getenv("PPLX_API_KEY") or os.getenv("OPENAI_API_KEY")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
rag_kb = RAGKnowledgeBase()
bot = Bot(token=BOT_TOKEN)
dp = Dispatcher(storage=MemoryStorage())

openai.api_key = PPLX_API_KEY
openai.api_base = "https://api.perplexity.ai"  # Perplexity endpoint

class ContentType(StatesGroup):
    POST = State()

@dp.message(Command("start"))
async def start_handler(message: Message):
    await message.answer(
        "ü§ñ AI Content Bot v2.0\n\n"
        "üìù –ù–∞–ø–∏—à–∏ —Ç–µ–º—É –ø–æ—Å—Ç–∞:\n"
        "‚Ä¢ SMM –ú–æ—Å–∫–≤–∞\n"
        "‚Ä¢ –ë—ã—Å—Ç—Ä—ã–π –∑–∞–≤—Ç—Ä–∞–∫\n\n"
        "üìö –ó–∞–≥—Ä—É–∑–∏ PDF/DOCX ‚Üí RAG –±–∞–∑–∞"
    )

@dp.message(Command("rag_status"))
async def rag_status(message: Message):
    status = "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ" if rag_kb.vectorstore else "üìö –ü—É—Å—Ç–æ"
    await message.answer(f"RAG: {status}")

@dp.message(lambda message: message.document)
async def upload_document(message: Message):
    file = await bot.get_file(message.document.file_id)
    file_path = f"rag/documents/{message.document.file_name}"
    
    await bot.download_file(file.file_path, file_path)
    await message.answer("üì• –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω –≤ RAG!")
    
    # –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º vectorstore
    docs = rag_kb.load_documents()
    rag_kb.create_vectorstore(docs)
    await message.answer("‚úÖ RAG –æ–±–Ω–æ–≤–ª—ë–Ω!")

@dp.message()
async def generate_content(message: Message, state: FSMContext):
    topic = message.text.strip()
    await message.answer(f"üî• –ì–µ–Ω–µ—Ä–∏—Ä—É—é –ø–æ—Å—Ç –¥–ª—è '{topic}'...")
    
    try:
        # ‚úÖ –§–ò–ö–°: –±–µ–∑–æ–ø–∞—Å–Ω—ã–π RAG
        knowledge = ""
        if rag_kb.vectorstore:
            knowledge = rag_kb.search(topic)
        
        # Perplexity –∑–∞–ø—Ä–æ—Å
        response = openai.ChatCompletion.create(
            model="llama-3.1-sonar-small-128k-online",
            messages=[
                {"role": "system", "content": "–°–æ–∑–¥–∞–π SMM –ø–æ—Å—Ç 200-300 —Å–ª–æ–≤. –≠–º–æ–¥–∑–∏, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞, –ø—Ä–∏–∑—ã–≤ –∫ –¥–µ–π—Å—Ç–≤–∏—é."},
                {"role": "user", "content": f"–¢–µ–º–∞: {topic}\nRAG: {knowledge}"}
            ],
            max_tokens=800,
            temperature=0.7
        )
        
        post_text = response.choices[0].message.content
        
        await message.answer(f"‚úÖ –ü–æ—Å—Ç –≥–æ—Ç–æ–≤!\n\n{post_text}")
        rag_status = "üìö RAG –ø—É—Å—Ç" if not knowledge else "‚úÖ RAG –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω!"
        await message.answer(rag_status)
        
    except Exception as e:
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")

async def main():
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
    print("ü§ñ Bot starting...")
    await dp.start_polling(bot)

async def main():
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
    await dp.start_polling(bot)  # ‚Üê –¢–í–û–Ø —Å—Ç—Ä–æ–∫–∞ –∏–∑ –∫–æ–¥–∞!

if __name__ == "__main__":
    asyncio.run(main())
